{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "tensor([1])\n",
      "torch.Size([1, 1, 1, 1])\n",
      "tensor([[[[1]]]])\n"
     ]
    }
   ],
   "source": [
    "# [:, None, None, None]的作用\n",
    "tensor = torch.tensor([1])\n",
    "print(tensor.shape)\n",
    "print(tensor)\n",
    "expanded_tensor = tensor[:, None, None, None]\n",
    "print(expanded_tensor.shape)\n",
    "print(expanded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.1111, -0.2222, -0.3333, -0.4444, -0.5556, -0.6667, -0.7778,\n",
      "        -0.8889, -1.0000])\n",
      "tensor([ 0.0000, -0.1111, -0.2222, -0.3333, -0.4444, -0.5556, -0.6667, -0.7778,\n",
      "        -0.8889, -1.0000])\n"
     ]
    }
   ],
   "source": [
    "# 数据类型推断\n",
    "beta = torch.linspace(1, 2, 10)\n",
    "alpha = 1.- beta\n",
    "print(alpha)\n",
    "alpha = 1- beta\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的张量：\n",
      "tensor([[[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]]])\n",
      "张量的形状： torch.Size([1, 3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros(1, 3, 2, 4)\n",
    "\n",
    "print(\"生成的张量：\")\n",
    "print(tensor)\n",
    "print(\"张量的形状：\", tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([128])\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[8.4147e-01, 8.0196e-01, 7.6172e-01, 7.2141e-01, 6.8156e-01, 6.4256e-01,\n",
       "         6.0469e-01, 5.6818e-01, 5.3317e-01, 4.9974e-01, 4.6795e-01, 4.3781e-01,\n",
       "         4.0931e-01, 3.8242e-01, 3.5711e-01, 3.3332e-01, 3.1098e-01, 2.9004e-01,\n",
       "         2.7043e-01, 2.5208e-01, 2.3492e-01, 2.1889e-01, 2.0391e-01, 1.8993e-01,\n",
       "         1.7689e-01, 1.6473e-01, 1.5338e-01, 1.4281e-01, 1.3296e-01, 1.2378e-01,\n",
       "         1.1522e-01, 1.0725e-01, 9.9833e-02, 9.2923e-02, 8.6488e-02, 8.0497e-02,\n",
       "         7.4919e-02, 6.9726e-02, 6.4893e-02, 6.0393e-02, 5.6204e-02, 5.2306e-02,\n",
       "         4.8678e-02, 4.5300e-02, 4.2157e-02, 3.9232e-02, 3.6509e-02, 3.3976e-02,\n",
       "         3.1618e-02, 2.9423e-02, 2.7381e-02, 2.5480e-02, 2.3712e-02, 2.2066e-02,\n",
       "         2.0534e-02, 1.9108e-02, 1.7782e-02, 1.6547e-02, 1.5399e-02, 1.4330e-02,\n",
       "         1.3335e-02, 1.2409e-02, 1.1548e-02, 1.0746e-02, 9.9998e-03, 9.3056e-03,\n",
       "         8.6595e-03, 8.0583e-03, 7.4989e-03, 6.9782e-03, 6.4938e-03, 6.0429e-03,\n",
       "         5.6234e-03, 5.2330e-03, 4.8697e-03, 4.5316e-03, 4.2170e-03, 3.9242e-03,\n",
       "         3.6517e-03, 3.3982e-03, 3.1623e-03, 2.9427e-03, 2.7384e-03, 2.5483e-03,\n",
       "         2.3714e-03, 2.2067e-03, 2.0535e-03, 1.9110e-03, 1.7783e-03, 1.6548e-03,\n",
       "         1.5399e-03, 1.4330e-03, 1.3335e-03, 1.2409e-03, 1.1548e-03, 1.0746e-03,\n",
       "         1.0000e-03, 9.3057e-04, 8.6596e-04, 8.0584e-04, 7.4989e-04, 6.9783e-04,\n",
       "         6.4938e-04, 6.0430e-04, 5.6234e-04, 5.2330e-04, 4.8697e-04, 4.5316e-04,\n",
       "         4.2170e-04, 3.9242e-04, 3.6517e-04, 3.3982e-04, 3.1623e-04, 2.9427e-04,\n",
       "         2.7384e-04, 2.5483e-04, 2.3714e-04, 2.2067e-04, 2.0535e-04, 1.9110e-04,\n",
       "         1.7783e-04, 1.6548e-04, 1.5399e-04, 1.4330e-04, 1.3335e-04, 1.2409e-04,\n",
       "         1.1548e-04, 1.0746e-04, 5.4030e-01, 5.9738e-01, 6.4791e-01, 6.9250e-01,\n",
       "         7.3176e-01, 7.6624e-01, 7.9646e-01, 8.2290e-01, 8.4601e-01, 8.6618e-01,\n",
       "         8.8376e-01, 8.9907e-01, 9.1240e-01, 9.2399e-01, 9.3406e-01, 9.4281e-01,\n",
       "         9.5042e-01, 9.5701e-01, 9.6274e-01, 9.6771e-01, 9.7201e-01, 9.7575e-01,\n",
       "         9.7899e-01, 9.8180e-01, 9.8423e-01, 9.8634e-01, 9.8817e-01, 9.8975e-01,\n",
       "         9.9112e-01, 9.9231e-01, 9.9334e-01, 9.9423e-01, 9.9500e-01, 9.9567e-01,\n",
       "         9.9625e-01, 9.9675e-01, 9.9719e-01, 9.9757e-01, 9.9789e-01, 9.9817e-01,\n",
       "         9.9842e-01, 9.9863e-01, 9.9881e-01, 9.9897e-01, 9.9911e-01, 9.9923e-01,\n",
       "         9.9933e-01, 9.9942e-01, 9.9950e-01, 9.9957e-01, 9.9963e-01, 9.9968e-01,\n",
       "         9.9972e-01, 9.9976e-01, 9.9979e-01, 9.9982e-01, 9.9984e-01, 9.9986e-01,\n",
       "         9.9988e-01, 9.9990e-01, 9.9991e-01, 9.9992e-01, 9.9993e-01, 9.9994e-01,\n",
       "         9.9995e-01, 9.9996e-01, 9.9996e-01, 9.9997e-01, 9.9997e-01, 9.9998e-01,\n",
       "         9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "         9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_encoding(t, channels):\n",
    "    inv_freq = 1.0 / (\n",
    "        10000\n",
    "        ** (torch.arange(0, channels, 2, device=\"cpu\").float() / channels)\n",
    "    )\n",
    "    print(t.shape)\n",
    "    print(inv_freq.shape)\n",
    "    pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "    print(pos_enc_a.shape)\n",
    "    pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "    pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "    return pos_enc\n",
    "\n",
    "tensor = torch.Tensor([1])\n",
    "new_tensor = pos_encoding(tensor, channels=256)\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1, 2],\n",
      "        [1, 2]])\n",
      "torch.Size([1, 1, 4, 6])\n",
      "tensor([[[[1, 2, 1, 2, 1, 2],\n",
      "          [1, 2, 1, 2, 1, 2],\n",
      "          [1, 2, 1, 2, 1, 2],\n",
      "          [1, 2, 1, 2, 1, 2]]]])\n",
      "torch.Size([1, 1, 1, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [1, 2]])\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print(x.repeat(1, 1, 2, 3).shape)\n",
    "print(x.repeat(1, 1, 2, 3))\n",
    "print(x.repeat(1, 1, 1, 2, 3).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "def get_data():\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(80),\n",
    "        torchvision.transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    dataset = torchvision.datasets.ImageFolder(r\"./data\", transform=transforms)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    return dataloader\n",
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([64, 3, 64, 64])\n",
      "Batch shape: torch.Size([64, 3, 64, 64])\n",
      "Batch shape: torch.Size([64, 3, 64, 64])\n",
      "Batch shape: torch.Size([64, 3, 64, 64])\n",
      "Batch shape: torch.Size([64, 3, 64, 64])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBatch shape:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\torchvision\\datasets\\folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\torchvision\\datasets\\folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\torchvision\\datasets\\folder.py:248\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    247\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\PIL\\Image.py:911\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m    865\u001b[0m ):\n\u001b[0;32m    866\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    913\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32me:\\anaconda3.0\\Lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in data:\n",
    "    inputs, labels = batch\n",
    "    print(\"Batch shape:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "ResNet\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 128, 1, 1])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "selfattention\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 1024, 128])\n",
      "torch.Size([2, 1024, 128])\n",
      "torch.Size([2, 1024, 128])\n",
      "torch.Size([2, 1024, 128])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "Down\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "ResNet\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 256, 1, 1])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "selfattention\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 256, 256])\n",
      "torch.Size([2, 256, 256])\n",
      "torch.Size([2, 256, 256])\n",
      "torch.Size([2, 256, 256])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "Down\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "ResNet\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 1, 1])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "selfattention\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 64, 256])\n",
      "torch.Size([2, 64, 256])\n",
      "torch.Size([2, 64, 256])\n",
      "torch.Size([2, 64, 256])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "mid\n",
      "ResNet\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 512, 8, 8])\n",
      "torch.Size([2, 512, 1, 1])\n",
      "torch.Size([2, 512, 8, 8])\n",
      "torch.Size([2, 512, 8, 8])\n",
      "torch.Size([2, 512, 8, 8])\n",
      "selfattention\n",
      "torch.Size([2, 512, 8, 8])\n",
      "torch.Size([2, 64, 512])\n",
      "torch.Size([2, 64, 512])\n",
      "torch.Size([2, 64, 512])\n",
      "torch.Size([2, 64, 512])\n",
      "torch.Size([2, 512, 8, 8])\n",
      "ResNet\n",
      "torch.Size([2, 512, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 1, 1])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "up\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 256, 16, 16])\n",
      "torch.Size([2, 512, 16, 16])\n",
      "ResNet\n",
      "torch.Size([2, 512, 16, 16])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 128, 1, 1])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "selfattention\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 256, 128])\n",
      "torch.Size([2, 256, 128])\n",
      "torch.Size([2, 256, 128])\n",
      "torch.Size([2, 256, 128])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "up\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 128, 32, 32])\n",
      "torch.Size([2, 256, 32, 32])\n",
      "ResNet\n",
      "torch.Size([2, 256, 32, 32])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 64, 1, 1])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "selfattention\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 1024, 64])\n",
      "torch.Size([2, 1024, 64])\n",
      "torch.Size([2, 1024, 64])\n",
      "torch.Size([2, 1024, 64])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "up\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 128, 64, 64])\n",
      "ResNet\n",
      "torch.Size([2, 128, 64, 64])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 64, 1, 1])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "selfattention\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 4096, 64])\n",
      "torch.Size([2, 4096, 64])\n",
      "torch.Size([2, 4096, 64])\n",
      "torch.Size([2, 4096, 64])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 64, 64, 64])\n",
      "torch.Size([2, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "from UNet import UNet\n",
    "import torch\n",
    "device = \"cpu\"\n",
    "model = UNet(device=device)\n",
    "t = torch.randn(2)\n",
    "x = torch.randn(2, 3, 64, 64)\n",
    "print(model(x, t).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorwatch as tw\n",
    "from UNet import UNet # 这是我自己定义的一个网络\n",
    " \n",
    "model = UNet()\n",
    "tw.draw_model(model, [1, 3, 64, 64])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
